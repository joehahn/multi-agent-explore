{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi_agent.ipynb\n",
    "#\n",
    "#by Joe Hahn\n",
    "#jmh.datasciences@gmail.com\n",
    "#12 February 2018\n",
    "#\n",
    "#This uses Q-learning on multiple agents to demonstrate something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game settings\n",
    "N_agents = 10                #number of agents\n",
    "N_buckets = 50               #number of buckets\n",
    "max_turns = 200             #max number of moves in single game\n",
    "turn = 0                    #current turn\n",
    "strategy = 'random'         #agents move randomly\n",
    "rn_seed = 14                #seed for random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import game\n",
    "from multi_agent import *\n",
    "import time\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotting libraries\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=1.5, font='DejaVu Sans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment =  {'max_turns': 200, 'rn_seed': 14, 'N_agents': 10, 'bucket_params': {'p0': array([ 0.        ,  0.00020408,  0.00040816,  0.00061224,  0.00081633,\n",
      "        0.00102041,  0.00122449,  0.00142857,  0.00163265,  0.00183673,\n",
      "        0.00204082,  0.0022449 ,  0.00244898,  0.00265306,  0.00285714,\n",
      "        0.00306122, -0.00326531, -0.00346939,  0.00367347,  0.00387755,\n",
      "        0.00408163,  0.00428571,  0.0044898 ,  0.00469388,  0.00489796,\n",
      "        0.00510204,  0.00530612,  0.0055102 ,  0.00571429,  0.00591837,\n",
      "        0.00612245,  0.00632653,  0.00653061,  0.00673469,  0.00693878,\n",
      "        0.00714286,  0.00734694,  0.00755102,  0.0077551 ,  0.00795918,\n",
      "        0.00816327,  0.00836735,  0.00857143,  0.00877551,  0.00897959,\n",
      "        0.00918367, -0.01267347, -0.01294898, -0.01322449, -0.0135    ]), 'sigma': array([ 0.        ,  0.01428571,  0.02020305,  0.02474358,  0.02857143,\n",
      "        0.03194383,  0.03499271,  0.03779645,  0.0404061 ,  0.04285714,\n",
      "        0.0451754 ,  0.04738035,  0.04948717,  0.05150788,  0.05345225,\n",
      "        0.05532833,  0.05714286,  0.05890151,  0.06060915,  0.06226998,\n",
      "        0.06388766,  0.06546537,  0.06700594,  0.06851188,  0.06998542,\n",
      "        0.07142857,  0.07284314,  0.07423075,  0.07559289,  0.07693093,\n",
      "        0.07824608,  0.07953949,  0.0808122 ,  0.08206518,  0.08329931,\n",
      "        0.08451543,  0.08571429,  0.08689661,  0.08806306,  0.08921426,\n",
      "        0.09035079,  0.0914732 ,  0.09258201,  0.09367769,  0.09476071,\n",
      "        0.09583148,  0.09689043,  0.09793792,  0.09897433,  0.1       ])}, 'N_buckets': 50}\n",
      "state =  {'agent_value': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), 'previous_bucket_productivity': array([ 0.        , -0.02360545, -0.05179113,  0.00453972, -0.04718636,\n",
      "       -0.01573653, -0.05366343,  0.0142344 , -0.01655507,  0.01975411,\n",
      "        0.0637218 , -0.00276   ,  0.04924256, -0.01826377, -0.04724774,\n",
      "       -0.05415791,  0.02725692,  0.05204999, -0.00920223,  0.08078838,\n",
      "        0.00756657, -0.05508455, -0.02008088,  0.03841251, -0.01457531,\n",
      "       -0.02877637,  0.01948764, -0.1195403 , -0.11222048,  0.00124887,\n",
      "       -0.08530099,  0.08833907, -0.0424717 ,  0.03037196, -0.07576688,\n",
      "       -0.04332359,  0.00947894, -0.09106583, -0.00247497, -0.00318968,\n",
      "        0.13183121,  0.07604157,  0.02723144,  0.13038356,  0.01050207,\n",
      "        0.15220481, -0.11269725,  0.01598478,  0.00574045, -0.14111101]), 'agent_locations': array([39, 32, 13, 47, 35, 14, 10, 21, 34, 40]), 'bucket_productivity': array([ 0.        ,  0.01130913, -0.01455369,  0.06003139,  0.00126401,\n",
      "        0.00205023, -0.06612535,  0.03785447, -0.03227411,  0.05789551,\n",
      "       -0.06594203, -0.06680877,  0.00614188,  0.0066948 , -0.05033239,\n",
      "        0.07081971, -0.11602674, -0.0533806 ,  0.09675792,  0.07268712,\n",
      "        0.15533584,  0.04173799, -0.17929007, -0.03962818, -0.01044237,\n",
      "        0.00888287,  0.02063993,  0.18928121,  0.07639939,  0.07676335,\n",
      "        0.02382805, -0.03418145, -0.01133601, -0.05890809, -0.0382545 ,\n",
      "        0.01964002,  0.05490928,  0.08853345,  0.09528416, -0.09384671,\n",
      "       -0.09606201, -0.09931076, -0.04687994, -0.01764484, -0.10986674,\n",
      "        0.00373388,  0.11760885,  0.11137841, -0.01482671, -0.10454532])}\n",
      "reward =  9.82367755605\n",
      "bucket_value =  [-0.09384671 -0.01133601  0.0066948   0.11137841  0.01964002 -0.05033239\n",
      " -0.06594203  0.04173799 -0.0382545  -0.09606201]\n",
      "state_vector =  [[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.          0.          0.          1.\n",
      "   1.          0.          0.          0.          0.          0.          0.\n",
      "   1.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          1.          0.          1.\n",
      "   1.          0.          0.          0.          1.          1.          0.\n",
      "   0.          0.          0.          0.          0.          1.          0.\n",
      "   0.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.          1.          0.         -0.02360545\n",
      "  -0.05179113  0.00453972 -0.04718636 -0.01573653 -0.05366343  0.0142344\n",
      "  -0.01655507  0.01975411  0.0637218  -0.00276     0.04924256 -0.01826377\n",
      "  -0.04724774 -0.05415791  0.02725692  0.05204999 -0.00920223  0.08078838\n",
      "   0.00756657 -0.05508455 -0.02008088  0.03841251 -0.01457531 -0.02877637\n",
      "   0.01948764 -0.1195403  -0.11222048  0.00124887 -0.08530099  0.08833907\n",
      "  -0.0424717   0.03037196 -0.07576688 -0.04332359  0.00947894 -0.09106583\n",
      "  -0.00247497 -0.00318968  0.13183121  0.07604157  0.02723144  0.13038356\n",
      "   0.01050207  0.15220481 -0.11269725  0.01598478  0.00574045 -0.14111101]]\n",
      "game_state =  running\n"
     ]
    }
   ],
   "source": [
    "#initialize system\n",
    "environment = initialize_environment(rn_seed, max_turns, N_buckets, N_agents)\n",
    "print 'environment = ', environment\n",
    "state = initialize_state(environment)\n",
    "print 'state = ', state\n",
    "reward, bucket_value = get_reward(state)\n",
    "print 'reward = ', reward\n",
    "print 'bucket_value = ', bucket_value\n",
    "state_vector = state2vector(state, environment)\n",
    "print 'state_vector = ', state_vector\n",
    "game_state = get_game_state(turn, environment)\n",
    "print 'game_state = ', game_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#illustrate moving an agent\n",
    "if ((N_agents == 3) and (N_buckets == 10)):\n",
    "    environment = initialize_environment(rn_seed, max_turns, N_buckets, N_agents)\n",
    "    state = initialize_state(environment)\n",
    "    print 'state = ', state\n",
    "    print 'strategy = ', strategy\n",
    "    state_moved, action = move_agents(state, environment, strategy)\n",
    "    print 'state_moved = ', state_moved\n",
    "    print 'action = ', action\n",
    "    reward, bucket_value = get_reward(state_moved)\n",
    "    print 'reward = ', reward\n",
    "    print 'bucket_value = ', bucket_value\n",
    "    state_next = update_state(state_moved, bucket_value, environment)\n",
    "    print 'state_next = ', state_next\n",
    "    state_vector_next = state2vector(state_next, environment)\n",
    "    print 'state_vector_next = ', state_vector_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of memories generated during 1 game =  200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn</th>\n",
       "      <th>reward</th>\n",
       "      <th>agent_value_0</th>\n",
       "      <th>agent_value_1</th>\n",
       "      <th>agent_value_2</th>\n",
       "      <th>agent_value_3</th>\n",
       "      <th>agent_value_4</th>\n",
       "      <th>agent_value_5</th>\n",
       "      <th>agent_value_6</th>\n",
       "      <th>agent_value_7</th>\n",
       "      <th>agent_value_8</th>\n",
       "      <th>agent_value_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>16.900462</td>\n",
       "      <td>1.854802</td>\n",
       "      <td>4.595453</td>\n",
       "      <td>0.387646</td>\n",
       "      <td>2.695966</td>\n",
       "      <td>0.956435</td>\n",
       "      <td>1.311412</td>\n",
       "      <td>1.253760</td>\n",
       "      <td>1.321549</td>\n",
       "      <td>1.205139</td>\n",
       "      <td>1.398735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>17.395461</td>\n",
       "      <td>1.883644</td>\n",
       "      <td>4.784250</td>\n",
       "      <td>0.393674</td>\n",
       "      <td>2.521678</td>\n",
       "      <td>0.967673</td>\n",
       "      <td>1.331805</td>\n",
       "      <td>1.147687</td>\n",
       "      <td>1.351256</td>\n",
       "      <td>1.195382</td>\n",
       "      <td>1.323412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>17.077734</td>\n",
       "      <td>1.934566</td>\n",
       "      <td>5.127153</td>\n",
       "      <td>0.336644</td>\n",
       "      <td>2.623994</td>\n",
       "      <td>1.025785</td>\n",
       "      <td>1.349465</td>\n",
       "      <td>1.169622</td>\n",
       "      <td>1.387785</td>\n",
       "      <td>1.228690</td>\n",
       "      <td>1.211759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>16.959896</td>\n",
       "      <td>1.853338</td>\n",
       "      <td>5.064076</td>\n",
       "      <td>0.347262</td>\n",
       "      <td>2.592600</td>\n",
       "      <td>1.035078</td>\n",
       "      <td>1.376552</td>\n",
       "      <td>1.038077</td>\n",
       "      <td>1.465710</td>\n",
       "      <td>1.127521</td>\n",
       "      <td>1.177521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>16.586210</td>\n",
       "      <td>1.957566</td>\n",
       "      <td>4.984875</td>\n",
       "      <td>0.356880</td>\n",
       "      <td>2.627492</td>\n",
       "      <td>1.035376</td>\n",
       "      <td>1.353041</td>\n",
       "      <td>0.960421</td>\n",
       "      <td>1.355142</td>\n",
       "      <td>1.030216</td>\n",
       "      <td>1.298888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     turn     reward  agent_value_0  agent_value_1  agent_value_2  \\\n",
       "195   195  16.900462       1.854802       4.595453       0.387646   \n",
       "196   196  17.395461       1.883644       4.784250       0.393674   \n",
       "197   197  17.077734       1.934566       5.127153       0.336644   \n",
       "198   198  16.959896       1.853338       5.064076       0.347262   \n",
       "199   199  16.586210       1.957566       4.984875       0.356880   \n",
       "\n",
       "     agent_value_3  agent_value_4  agent_value_5  agent_value_6  \\\n",
       "195       2.695966       0.956435       1.311412       1.253760   \n",
       "196       2.521678       0.967673       1.331805       1.147687   \n",
       "197       2.623994       1.025785       1.349465       1.169622   \n",
       "198       2.592600       1.035078       1.376552       1.038077   \n",
       "199       2.627492       1.035376       1.353041       0.960421   \n",
       "\n",
       "     agent_value_7  agent_value_8  agent_value_9  \n",
       "195       1.321549       1.205139       1.398735  \n",
       "196       1.351256       1.195382       1.323412  \n",
       "197       1.387785       1.228690       1.211759  \n",
       "198       1.465710       1.127521       1.177521  \n",
       "199       1.355142       1.030216       1.298888  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#play 1 game of randomly-moving agents and stash history in dataframe\n",
    "strategy = 'random'\n",
    "memories = play_one_game(environment, strategy)\n",
    "game_history, locations_rewards = memories2timeseries(memories, environment)\n",
    "print 'number of memories generated during 1 game = ', len(memories)\n",
    "game_history.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>locations</th>\n",
       "      <th>reward</th>\n",
       "      <th>N_visits</th>\n",
       "      <th>reward_per_agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0, 1, 3, 6, 6, 9, 18, 23, 32, 44</td>\n",
       "      <td>17.905482</td>\n",
       "      <td>1</td>\n",
       "      <td>1.790548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12, 19, 20, 21, 32, 33, 35, 35, 43, 49</td>\n",
       "      <td>17.884263</td>\n",
       "      <td>1</td>\n",
       "      <td>1.788426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0, 12, 13, 20, 25, 27, 29, 45, 45, 49</td>\n",
       "      <td>17.881510</td>\n",
       "      <td>1</td>\n",
       "      <td>1.788151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1, 6, 7, 13, 14, 17, 17, 27, 35, 41</td>\n",
       "      <td>17.842121</td>\n",
       "      <td>1</td>\n",
       "      <td>1.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3, 3, 9, 16, 23, 27, 38, 44, 46, 47</td>\n",
       "      <td>17.785685</td>\n",
       "      <td>1</td>\n",
       "      <td>1.778569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6, 9, 15, 16, 33, 34, 35, 40, 48, 49</td>\n",
       "      <td>17.783577</td>\n",
       "      <td>1</td>\n",
       "      <td>1.778358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2, 11, 24, 28, 33, 34, 35, 40, 46, 46</td>\n",
       "      <td>17.612721</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5, 12, 17, 18, 23, 23, 35, 41, 42, 43</td>\n",
       "      <td>17.557788</td>\n",
       "      <td>1</td>\n",
       "      <td>1.755779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>12, 12, 16, 16, 21, 24, 29, 32, 40, 44</td>\n",
       "      <td>17.532246</td>\n",
       "      <td>1</td>\n",
       "      <td>1.753225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0, 5, 7, 10, 16, 18, 19, 20, 30, 47</td>\n",
       "      <td>17.527729</td>\n",
       "      <td>1</td>\n",
       "      <td>1.752773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>8, 9, 12, 20, 20, 22, 32, 36, 42, 48</td>\n",
       "      <td>17.514553</td>\n",
       "      <td>1</td>\n",
       "      <td>1.751455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>9, 14, 20, 27, 28, 31, 32, 34, 45, 48</td>\n",
       "      <td>17.501417</td>\n",
       "      <td>1</td>\n",
       "      <td>1.750142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4, 10, 16, 25, 27, 30, 39, 40, 48, 48</td>\n",
       "      <td>17.395461</td>\n",
       "      <td>1</td>\n",
       "      <td>1.739546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>8, 11, 11, 13, 18, 19, 40, 43, 43, 47</td>\n",
       "      <td>17.392303</td>\n",
       "      <td>1</td>\n",
       "      <td>1.739230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>12, 22, 24, 25, 25, 42, 43, 47, 48, 49</td>\n",
       "      <td>17.248925</td>\n",
       "      <td>1</td>\n",
       "      <td>1.724892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1, 10, 14, 36, 36, 38, 40, 41, 43, 43</td>\n",
       "      <td>17.189610</td>\n",
       "      <td>1</td>\n",
       "      <td>1.718961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>3, 8, 12, 19, 21, 26, 32, 32, 43, 47</td>\n",
       "      <td>17.171153</td>\n",
       "      <td>1</td>\n",
       "      <td>1.717115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0, 3, 3, 10, 12, 33, 35, 45, 45, 46</td>\n",
       "      <td>17.150521</td>\n",
       "      <td>1</td>\n",
       "      <td>1.715052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5, 7, 15, 16, 18, 21, 23, 25, 39, 45</td>\n",
       "      <td>17.122619</td>\n",
       "      <td>1</td>\n",
       "      <td>1.712262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>8, 10, 15, 17, 24, 29, 31, 37, 38, 48</td>\n",
       "      <td>17.077734</td>\n",
       "      <td>1</td>\n",
       "      <td>1.707773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    action                               locations     reward  N_visits  \\\n",
       "0        0        0, 1, 3, 6, 6, 9, 18, 23, 32, 44  17.905482         1   \n",
       "1        1  12, 19, 20, 21, 32, 33, 35, 35, 43, 49  17.884263         1   \n",
       "2        2   0, 12, 13, 20, 25, 27, 29, 45, 45, 49  17.881510         1   \n",
       "3        3     1, 6, 7, 13, 14, 17, 17, 27, 35, 41  17.842121         1   \n",
       "4        4     3, 3, 9, 16, 23, 27, 38, 44, 46, 47  17.785685         1   \n",
       "5        5    6, 9, 15, 16, 33, 34, 35, 40, 48, 49  17.783577         1   \n",
       "6        6   2, 11, 24, 28, 33, 34, 35, 40, 46, 46  17.612721         1   \n",
       "7        7   5, 12, 17, 18, 23, 23, 35, 41, 42, 43  17.557788         1   \n",
       "8        8  12, 12, 16, 16, 21, 24, 29, 32, 40, 44  17.532246         1   \n",
       "9        9     0, 5, 7, 10, 16, 18, 19, 20, 30, 47  17.527729         1   \n",
       "10      10    8, 9, 12, 20, 20, 22, 32, 36, 42, 48  17.514553         1   \n",
       "11      11   9, 14, 20, 27, 28, 31, 32, 34, 45, 48  17.501417         1   \n",
       "12      12   4, 10, 16, 25, 27, 30, 39, 40, 48, 48  17.395461         1   \n",
       "13      13   8, 11, 11, 13, 18, 19, 40, 43, 43, 47  17.392303         1   \n",
       "14      14  12, 22, 24, 25, 25, 42, 43, 47, 48, 49  17.248925         1   \n",
       "15      15   1, 10, 14, 36, 36, 38, 40, 41, 43, 43  17.189610         1   \n",
       "16      16    3, 8, 12, 19, 21, 26, 32, 32, 43, 47  17.171153         1   \n",
       "17      17     0, 3, 3, 10, 12, 33, 35, 45, 45, 46  17.150521         1   \n",
       "18      18    5, 7, 15, 16, 18, 21, 23, 25, 39, 45  17.122619         1   \n",
       "19      19   8, 10, 15, 17, 24, 29, 31, 37, 38, 48  17.077734         1   \n",
       "\n",
       "    reward_per_agent  \n",
       "0           1.790548  \n",
       "1           1.788426  \n",
       "2           1.788151  \n",
       "3           1.784212  \n",
       "4           1.778569  \n",
       "5           1.778358  \n",
       "6           1.761272  \n",
       "7           1.755779  \n",
       "8           1.753225  \n",
       "9           1.752773  \n",
       "10          1.751455  \n",
       "11          1.750142  \n",
       "12          1.739546  \n",
       "13          1.739230  \n",
       "14          1.724892  \n",
       "15          1.718961  \n",
       "16          1.717115  \n",
       "17          1.715052  \n",
       "18          1.712262  \n",
       "19          1.707773  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = locations_rewards.groupby('locations', as_index=False).agg({'reward':sum, 'N_visits':sum})\n",
    "actions['reward_per_agent'] = actions['reward']*1.0/actions['N_visits']/N_agents\n",
    "actions = actions.sort_values('reward_per_agent', ascending=False).reset_index(drop=True)\n",
    "actions['action'] = actions.index\n",
    "cols = ['action', 'locations', 'reward', 'N_visits', 'reward_per_agent']\n",
    "actions = actions[cols]\n",
    "actions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = memories[-1]\n",
    "#state = m[1]\n",
    "#action2locations = pd.DataFrame(state['action2locations'].copy())\n",
    "#action2locations\n",
    "#N = action2locations.groupby('locations_str', as_index=False).agg({'reward':sum, 'N_times':sum})\n",
    "#N['reward_rate'] = N['reward']*1.0/N['N_times']\n",
    "#N = N.sort_values('reward_rate', ascending=False).reset_index(drop=True)\n",
    "#N['action'] = N.index\n",
    "#cols = ['action', 'locations_str', 'reward', 'N_times', 'reward_rate']\n",
    "#N = N[cols]\n",
    "#N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot relative reward versus turn, and agent values vs turn\n",
    "df = game_history\n",
    "xp = df['turn']\n",
    "yp = df['reward']/df['reward'][0]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('relative reward vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward/reward[0]')\n",
    "p = ax.plot(xp, yp)\n",
    "#plot agents value versus turn\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('agent value vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('agent value')\n",
    "for col in df.columns:\n",
    "    if ('agent_value_' in col):\n",
    "        yp = df[col]\n",
    "        p = ax.plot(xp, df[col], label=col)\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play a low-risk, low-reward game with all agents moving randomly among the lower third of buckets\n",
    "strategy = 'low'\n",
    "memories = play_one_game(environment, strategy)\n",
    "game_history = memories2timeseries(memories, environment)\n",
    "df = game_history\n",
    "xp = df['turn']\n",
    "yp = df['reward']/df['reward'][0]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('relative reward vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward/reward[0]')\n",
    "p = ax.plot(xp, yp)\n",
    "#plot agents value versus turn\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('agent value vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('agent value')\n",
    "for col in df.columns:\n",
    "    if ('agent_value_' in col):\n",
    "        yp = df[col]\n",
    "        p = ax.plot(xp, df[col], label=col)\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play a medium-risk, medium-reward game with all agents moving randomly among the middle third of buckets\n",
    "strategy = 'middle'\n",
    "memories = play_one_game(environment, strategy)\n",
    "game_history = memories2timeseries(memories, environment)\n",
    "df = game_history\n",
    "xp = df['turn']\n",
    "yp = df['reward']/df['reward'][0]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('relative reward vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward/reward[0]')\n",
    "p = ax.plot(xp, yp)\n",
    "#plot agents value versus turn\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('agent value vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('agent value')\n",
    "for col in df.columns:\n",
    "    if ('agent_value_' in col):\n",
    "        yp = df[col]\n",
    "        p = ax.plot(xp, df[col], label=col)\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play a high-risk, high-reward game with all agents moving randomly among the upper third of buckets\n",
    "strategy = 'high'\n",
    "memories = play_one_game(environment, strategy)\n",
    "game_history = memories2timeseries(memories, environment)\n",
    "df = game_history\n",
    "xp = df['turn']\n",
    "yp = df['reward']/df['reward'][0]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('relative reward vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward/reward[0]')\n",
    "p = ax.plot(xp, yp)\n",
    "#plot agents value versus turn\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('agent value vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('agent value')\n",
    "for col in df.columns:\n",
    "    if ('agent_value_' in col):\n",
    "        yp = df[col]\n",
    "        p = ax.plot(xp, df[col], label=col)\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play 100 games using each strategy, and generate stats for each strategy\n",
    "N_games = 100\n",
    "strategies = ['low', 'middle', 'random', 'high']#, 'best']\n",
    "game_histories = pd.DataFrame()\n",
    "for strategy in strategies:\n",
    "    print 'strategy = ', strategy \n",
    "    for game in range(N_games):\n",
    "        turn = 0\n",
    "        memories = play_one_game(environment, strategy)\n",
    "        game_history = memories2timeseries(memories, environment)\n",
    "        game_history['strategy'] = strategy\n",
    "        game_history['game'] = game\n",
    "        game_histories = game_histories.append(game_history)\n",
    "game_stats = game_histories.groupby(['strategy', 'turn'])['reward'].agg(['mean', 'std'])\n",
    "game_stats['std'] /= np.sqrt(N_games - 1)\n",
    "game_stats.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot average agent value vs turn, for each strategy\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 8))\n",
    "p = ax.set_title('mean agent value vs strategy')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('mean agent value')\n",
    "for strategy in strategies:\n",
    "    reward = game_stats['mean'][strategy]\n",
    "    std = game_stats['std'][strategy]\n",
    "    std /= reward[0]\n",
    "    reward /= reward[0]\n",
    "    xp = reward.index\n",
    "    yp = reward.values\n",
    "    err = std.values\n",
    "    p = ax.plot(xp, yp, label=strategy, markersize=4, marker='o')\n",
    "    ax.errorbar(xp, yp, yerr=std, alpha=0.4, color=p[0].get_color())\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play 10 games making random actions, and stash moves in memories queue\n",
    "N_games = 10\n",
    "strategy = 'random'\n",
    "memories = play_N_games(environment, strategy, N_games)\n",
    "print 'number of memories = ', len(memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build queue of actions and rewards\n",
    "N_actions = 10\n",
    "actions_list = []\n",
    "for memory in memories:\n",
    "    turn, state, locations, state_next, reward, game_state = memory\n",
    "    locations.sort()\n",
    "    actions_list += [(locations, reward)]\n",
    "actions = deque(maxlen=N_actions)\n",
    "for j in range(N_actions):\n",
    "    actions.append(random.choice(actions_list))\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "N_inputs = state_vector.shape[1]\n",
    "N_outputs = N_actions\n",
    "N_neurons = 100\n",
    "model = build_model(N_inputs, N_neurons, N_outputs)\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train model\n",
    "N_games = 20                               #number of games played during training\n",
    "gamma = 0.85                                #discount for future rewards\n",
    "batch_size = 100                             #number of memories used during experience-replay\n",
    "debug = False                               #set True to see stats about each game's final turn\n",
    "print 'batch_size = ', batch_size\n",
    "print 'training model'\n",
    "trained_model, game, rewards, epsilon = train(environment, model, N_games, gamma, memories, actions, batch_size, debug=debug)\n",
    "print '\\ntraining done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot rewards vs training game\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = game\n",
    "yp = rewards\n",
    "p = ax.plot(xp, yp)\n",
    "p = ax.set_title('reward vs training game')\n",
    "p = ax.set_xlabel('game')\n",
    "p = ax.set_ylabel('final reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot epsilon vs game_number\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = game\n",
    "yp = epsilon\n",
    "p = ax.plot(xp, yp)\n",
    "p = ax.set_title('epsilon vs game number')\n",
    "p = ax.set_xlabel('game number')\n",
    "p = ax.set_ylabel('epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#play one smart game\n",
    "strategy = 'smart'\n",
    "memories = play_one_game(environment, turn, strategy, model=trained_model)\n",
    "game_history = memories2timeseries(memories, environment)\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = game_history['turn']\n",
    "yp = game_history['reward']\n",
    "p = ax.plot(xp, yp)\n",
    "p = ax.set_title('reward vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward')\n",
    "game_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show grayscale of agent locations\n",
    "cols = [col for col in game_history.columns if ('agents_' in col)]\n",
    "df = game_history[cols]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "plt.imshow(df.T, aspect='auto', cmap='gray')\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bucket rewards versus turn\n",
    "cols = ['turn'] + [col for col in game_history.columns if ('reward_' in col)]\n",
    "df = game_history[cols].drop_duplicates()\n",
    "cols = cols[1:]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 11))\n",
    "p = ax.set_title('bucket rewards')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward')\n",
    "p = ax.set_xlim(0, df['turn'].max() + 40)\n",
    "for col in cols:\n",
    "    p = ax.plot(df['turn'], df[col], alpha=0.8, linewidth=1, label=col)\n",
    "p = ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done!\n",
    "time_stop = time.time()\n",
    "print 'execution time (minutes) = ', (time_stop - time_start)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.append?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.array([0, 2, 5])\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(loc.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s='[1,2,3]'\n",
    "s.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
