{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi_agent.ipynb\n",
    "#\n",
    "#by Joe Hahn\n",
    "#jmh.datasciences@gmail.com\n",
    "#12 February 2018\n",
    "#\n",
    "#This uses Q-learning on multiple agents to demonstrate something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game settings\n",
    "N_agents = 3                #number of agents\n",
    "N_buckets = 7               #number of buckets\n",
    "max_turns = 400             #max number of moves in single game\n",
    "turn = 0                     #starting turn\n",
    "rn_seed = 14                 #seed for random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import game\n",
    "from multi_agent import *\n",
    "import time\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotting libraries\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=1.5, font='DejaVu Sans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment =  {'max_turns': 400, 'acts': ['move to 0', 'move to 1', 'move to 2', 'move to 3', 'move to 4', 'move to 5', 'move to 6'], 'actions': array([0, 1, 2, 3, 4, 5, 6]), 'N_agents': 3, 'rn_seed': 14, 'N_buckets': 7, 'bucket_params': {'p0': array([ 0.5       ,  0.66666667,  0.83333333,  1.        ,  1.16666667,\n",
      "        1.33333333,  1.5       ]), 'sigma': array([ 0.25      ,  0.70833333,  1.16666667,  1.625     ,  2.08333333,\n",
      "        2.54166667,  3.        ])}}\n",
      "state =  {'bucket_productivity': array([ 0.41722224,  1.38916186, -0.25692234, -0.2798226 ,  2.30735468,\n",
      "       -1.35731516, -1.48156123]), 'previous_bucket_productivity': array([ 0.11870634, -0.27661734,  0.6219043 ,  0.35564602, -2.8927732 ,\n",
      "        2.96604474,  0.68625791]), 'agent_health': array([ 1.,  1.,  1.]), 'agent_locations': array([2, 3, 1])}\n",
      "reward =  0.85241692463\n",
      "state_vector =  [[ 0.          1.          1.          1.          0.          0.          0.\n",
      "   0.11870634 -0.27661734  0.6219043   0.35564602 -2.8927732   2.96604474\n",
      "   0.68625791]]\n",
      "game_state =  running\n"
     ]
    }
   ],
   "source": [
    "#initialize system\n",
    "environment = initialize_environment(rn_seed, max_turns, N_buckets, N_agents)\n",
    "print 'environment = ', environment\n",
    "state = initialize_state(environment)\n",
    "print 'state = ', state\n",
    "reward = get_reward(state)\n",
    "print 'reward = ', reward\n",
    "state_vector = state2vector(state, environment)\n",
    "print 'state_vector = ', state_vector\n",
    "game_state = get_game_state(turn, environment)\n",
    "print 'game_state = ', game_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_locations =  [6 4 2]\n",
      "state_next =  {'bucket_productivity': array([ 0.56596566,  1.29025915, -0.21805664,  2.48086245, -0.09405033,\n",
      "        0.27678673,  0.56844213]), 'previous_bucket_productivity': array([ 0.33454106,  1.08174899,  1.23182195,  0.35917174,  1.79781868,\n",
      "       -4.80692034,  5.87749537]), 'agent_health': array([ 1.,  1.,  1.]), 'agent_locations': array([6, 4, 2])}\n",
      "state_vector_next =  [[ 0.          0.          1.          0.          1.          0.          1.\n",
      "   0.33454106  1.08174899  1.23182195  0.35917174  1.79781868 -4.80692034\n",
      "   5.87749537]]\n",
      "(3,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "#illustrate moving an agent\n",
    "new_locations = np.array([6, 4, 2])\n",
    "state_next = move_agent(state, new_locations)\n",
    "print 'new_locations = ', new_locations\n",
    "print 'state_next = ', state_next\n",
    "state_vector_next = state2vector(state_next, environment)\n",
    "print 'state_vector_next = ', state_vector_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play 1 game of randomly-moving agents and stash bucket rewards in dataframe\n",
    "turn = 0\n",
    "strategy = 'random'\n",
    "memories = play_one_game(environment, turn, strategy)\n",
    "game_history = memories2timeseries(memories, environment)\n",
    "print 'number of memories generated during 1 game = ', len(memories)\n",
    "print memories[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot bucket rewards versus turn\n",
    "cols = ['turn'] + [col for col in game_history.columns if ('reward_' in col)]\n",
    "df = game_history[cols].drop_duplicates()\n",
    "cols = cols[1:]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 11))\n",
    "p = ax.set_title('bucket rewards')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward')\n",
    "p = ax.set_xlim(0, df['turn'].max() + 40)\n",
    "for col in cols:\n",
    "    p = ax.plot(df['turn'], df[col], alpha=0.8, linewidth=1, label=col)\n",
    "p = ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play 10 games making random actions, and stash moves in memories queue\n",
    "N_games = 5\n",
    "strategy = 'random'\n",
    "memories = play_N_games(environment, strategy, N_games)\n",
    "print 'number of memories = ', len(memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "N_inputs = state_vector.shape[1]\n",
    "N_outputs = N_buckets\n",
    "N_neurons = N_inputs*N_outputs\n",
    "model = build_model(N_inputs, N_neurons, N_outputs)\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train model\n",
    "N_games = 20                               #number of games played during training\n",
    "gamma = 0.85                                #discount for future rewards\n",
    "batch_size = 100                             #number of memories used during experience-replay\n",
    "debug = False                               #set True to see stats about each game's final turn\n",
    "print 'batch_size = ', batch_size\n",
    "print 'training model'\n",
    "trained_model, game, rewards, epsilon = train(environment, model, N_games, gamma, memories, batch_size, debug=debug)\n",
    "print '\\ntraining done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot rewards vs training game\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = game\n",
    "yp = rewards\n",
    "p = ax.plot(xp, yp)\n",
    "p = ax.set_title('reward vs training game')\n",
    "p = ax.set_xlabel('game')\n",
    "p = ax.set_ylabel('final reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot epsilon vs game_number\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = game\n",
    "yp = epsilon\n",
    "p = ax.plot(xp, yp)\n",
    "p = ax.set_title('epsilon vs game number')\n",
    "p = ax.set_xlabel('game number')\n",
    "p = ax.set_ylabel('epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#play one smart game\n",
    "strategy = 'smart'\n",
    "memories = play_one_game(environment, turn, strategy, model=trained_model)\n",
    "game_history = memories2timeseries(memories, environment)\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = game_history['turn']\n",
    "yp = game_history['reward']\n",
    "p = ax.plot(xp, yp)\n",
    "p = ax.set_title('reward vs turn')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward')\n",
    "game_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show grayscale of agent locations\n",
    "cols = [col for col in game_history.columns if ('agents_' in col)]\n",
    "df = game_history[cols]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "plt.imshow(df.T, aspect='auto', cmap='gray')\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bucket rewards versus turn\n",
    "cols = ['turn'] + [col for col in game_history.columns if ('reward_' in col)]\n",
    "df = game_history[cols].drop_duplicates()\n",
    "cols = cols[1:]\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 11))\n",
    "p = ax.set_title('bucket rewards')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.set_ylabel('reward')\n",
    "p = ax.set_xlim(0, df['turn'].max() + 40)\n",
    "for col in cols:\n",
    "    p = ax.plot(df['turn'], df[col], alpha=0.8, linewidth=1, label=col)\n",
    "p = ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done!\n",
    "time_stop = time.time()\n",
    "print 'execution time (minutes) = ', (time_stop - time_start)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
